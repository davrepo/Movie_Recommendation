{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a random walk sampling of this network. Sample 2,000 nodes (1% of the network) and all their connections (note: the sample will end up having more than 2,000 nodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import networkx as nx\n",
    "\n",
    "G = nx.read_edgelist(\"data.txt\", nodetype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to keep track of the nodes and the edges we have sampled, so we store them in sets.\n",
    "# Then we need a seed node where to start the exploration. Here I decided to just pick a random node.\n",
    "sampled_nodes = set()\n",
    "sampled_edges = set()\n",
    "curnode = random.choice(list(G.nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We continue until we sampled 2000 nodes.\n",
    "while len(sampled_nodes) <= 2000:\n",
    "   # First we get the neighbors of the node we're currently exploring\n",
    "   neighbors = list(G.neighbors(curnode))\n",
    "   if not curnode in sampled_nodes: # This is true if we never sampled this node before. This means we never added its connections to sampled_edges\n",
    "      sampled_nodes.add(curnode) # This will allow us to remember we sampled this node\n",
    "      # We update the set of sampled edges. We need to have a canonical representation of the edge because the network is undirected,\n",
    "      # so if we already saw the edge because we sampled the neighbor, we might have stored the edge as (neighbor, curnode) rather than\n",
    "      # (curnode, neighbor). With this min-max trick, this is not an issue.\n",
    "      sampled_edges |= set([(min(curnode, neighbor), max(curnode, neighbor)) for neighbor in neighbors])\n",
    "   curnode = random.choice(neighbors) # We move on to sampling a random neighbor of the current node, because we're doing a r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jackh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\__init__.py:177: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62732\n"
     ]
    }
   ],
   "source": [
    "G_smpl = nx.Graph(list(sampled_edges))\n",
    "print(len(G_smpl.nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the CCDF of the degree distribution of your sample of the network from Exercise 25.1 with the one of the original network by fitting a log-log regression and comparing the exponents. You can take multiple samples from different seeds to ensure the robustness of your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Function implementing the random walk logic from the previous question\n",
    "def rw(G, n):\n",
    "   sampled_nodes = set()\n",
    "   sampled_edges = set()\n",
    "   curnode = random.choice(list(G.nodes))\n",
    "   while len(sampled_nodes) <= n:\n",
    "      neighbors = list(G.neighbors(curnode))\n",
    "      if not curnode in sampled_nodes:\n",
    "         sampled_nodes.add(curnode)\n",
    "         sampled_edges |= set([(min(curnode, neighbor), max(curnode, neighbor)) for neighbor in neighbors])\n",
    "      curnode = random.choice(neighbors)\n",
    "   return nx.Graph(list(sampled_edges))\n",
    "\n",
    "# Function generating a CCDF, from previous exercises\n",
    "def ccdf(dd):\n",
    "   dd = pd.DataFrame(list(dd.items()), columns = (\"k\", \"count\")).sort_values(by = \"k\")\n",
    "   ccdf = dd.sort_values(by = \"k\", ascending = False)\n",
    "   ccdf[\"cumsum\"] = ccdf[\"count\"].cumsum()\n",
    "   ccdf[\"ccdf\"] = ccdf[\"cumsum\"] / ccdf[\"count\"].sum()\n",
    "   ccdf = ccdf[[\"k\", \"ccdf\"]].sort_values(by = \"k\")\n",
    "   return ccdf\n",
    "\n",
    "# Function performing a simple regression in log-log space\n",
    "def dd_exponent(degdistr):\n",
    "   logcdf = np.log10(degdistr[[\"k\", \"ccdf\"]])\n",
    "   slope, log10intercept, r_value, p_value, std_err = linregress(logcdf[\"k\"], logcdf[\"ccdf\"])\n",
    "   return slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Exponent: -1.6013\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_edgelist(\"data.txt\", nodetype = int)\n",
    "G_ccdf = ccdf(Counter(dict(G.degree).values()))\n",
    "print(\"Original Exponent: %1.4f\" % dd_exponent(G_ccdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take 100 samples and store their degree exponent in a list\n",
    "smpl_exponents = []\n",
    "for _ in range(100):\n",
    "   G_smpl = rw(G, 2000)\n",
    "   G_smpl_ccdf = ccdf(Counter(dict(G_smpl.degree).values()))\n",
    "   smpl_exponents.append(dd_exponent(G_smpl_ccdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Exponent: -1.1259 (+/- 0.0104)\n"
     ]
    }
   ],
   "source": [
    "smpl_exponents_mean = np.mean(smpl_exponents)\n",
    "smpl_exponents_std = np.std(smpl_exponents)\n",
    "print(\"Sample Exponent: %1.4f (+/- %1.4f)\" % (smpl_exponents_mean, smpl_exponents_std)) # The exponent of the sample is diffe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the degree distribution of your sample of the network from Exercise 25.1 using the Re-Weighted Random Walk technique. Is the estimation of the exponent of the CCDF more precise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Function implementing the random walk logic from the previous question\n",
    "def rw(G, n):\n",
    "   sampled_nodes = set()\n",
    "   sampled_edges = set()\n",
    "   curnode = random.choice(list(G.nodes))\n",
    "   while len(sampled_nodes) <= n:\n",
    "      neighbors = list(G.neighbors(curnode))\n",
    "      if not curnode in sampled_nodes:\n",
    "         sampled_nodes.add(curnode)\n",
    "         sampled_edges |= set([(min(curnode, neighbor), max(curnode, neighbor)) for neighbor in neighbors])\n",
    "      curnode = random.choice(neighbors)\n",
    "   return nx.Graph(list(sampled_edges))\n",
    "\n",
    "# Function implementing the RWRW correction\n",
    "def rwrw(dd_smpl, nnodes):\n",
    "   dd_smpl = pd.DataFrame(dd_smpl, columns = (\"k\",))\n",
    "   dd_smpl[\"k_inv\"] = 1.0 / dd_smpl[\"k\"] # We need to calculate all x^{-1} values\n",
    "   denominator = dd_smpl[\"k_inv\"].sum() # The denominator of RWRW is simply their sum\n",
    "   dd_smpl = dd_smpl.groupby(by = \"k\").sum().reset_index() # For every value in the degree distribution, we need the sum of its inverse (numerator)\n",
    "   dd_smpl[\"p\"] = dd_smpl[\"k_inv\"] / denominator # Making the fraction\n",
    "   # So far we have the probability of observing a value. We want instead the number of nodes with that value.\n",
    "   # So we multiply the probability by the number of nodes in the sample.\n",
    "   dd_smpl[\"count\"] = dd_smpl[\"p\"] * nnodes\n",
    "   # Now we generate and return the CCDF as usual\n",
    "   ccdf = dd_smpl.sort_values(by = \"k\", ascending = False)\n",
    "   ccdf[\"cumsum\"] = ccdf[\"count\"].cumsum()\n",
    "   ccdf[\"ccdf\"] = ccdf[\"cumsum\"] / ccdf[\"count\"].sum()\n",
    "   ccdf = ccdf[[\"k\", \"ccdf\"]].sort_values(by = \"k\")\n",
    "   return ccdf\n",
    "\n",
    "# Function generating a CCDF, from previous exercises\n",
    "def ccdf(dd):\n",
    "   dd = pd.DataFrame(list(dd.items()), columns = (\"k\", \"count\")).sort_values(by = \"k\")\n",
    "   ccdf = dd.sort_values(by = \"k\", ascending = False)\n",
    "   ccdf[\"cumsum\"] = ccdf[\"count\"].cumsum()\n",
    "   ccdf[\"ccdf\"] = ccdf[\"cumsum\"] / ccdf[\"count\"].sum()\n",
    "   ccdf = ccdf[[\"k\", \"ccdf\"]].sort_values(by = \"k\")\n",
    "   return ccdf\n",
    "\n",
    "# Function performing a simple regression in log-log space\n",
    "def dd_exponent(degdistr):\n",
    "   logcdf = np.log10(degdistr[[\"k\", \"ccdf\"]])\n",
    "   slope, log10intercept, r_value, p_value, std_err = linregress(logcdf[\"k\"], logcdf[\"ccdf\"])\n",
    "   return slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Exponent: -1.6013\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_edgelist(\"data.txt\", nodetype = int)\n",
    "G_ccdf = ccdf(Counter(dict(G.degree).values()))\n",
    "print(\"Original Exponent: %1.4f\" % dd_exponent(G_ccdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take 50 samples and store their degree exponent in a list\n",
    "smpl_exponents = []\n",
    "for _ in range(100):\n",
    "   G_smpl = rw(G, 2000)\n",
    "   G_smpl_ccdf = rwrw(list(dict(G_smpl.degree()).values()), len(G_smpl.nodes))\n",
    "   smpl_exponents.append(dd_exponent(G_smpl_ccdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Exponent: -2.0982 (+/- 0.0129)\n"
     ]
    }
   ],
   "source": [
    "smpl_exponents_mean = np.mean(smpl_exponents)\n",
    "smpl_exponents_std = np.std(smpl_exponents)\n",
    "print(\"Sample Exponent: %1.4f (+/- %1.4f)\" % (smpl_exponents_mean, smpl_exponents_std)) # The correction moves the RW sample exponent from ~1.1 to ~2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify your random walk sampler for the network from Exercise 25.1 so that it applies the Metropolis-Hastings correction. Is the estimation of the exponent of the CCDF more precise? Is MHRW more or less precise than RWRW?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Exponent: -1.6013\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_edgelist(\"data.txt\", nodetype = int)\n",
    "G_ccdf = ccdf(Counter(dict(G.degree).values()))\n",
    "print(\"Original Exponent: %1.4f\" % dd_exponent(G_ccdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function implementing the random walk logic from the previous question, plus the Metropolis-Hastings correction\n",
    "def mhrw(G, n):\n",
    "   sampled_nodes = set()\n",
    "   sampled_edges = set()\n",
    "   curnode = random.choice(list(G.nodes))\n",
    "   while len(sampled_nodes) <= n:\n",
    "      neighbors = list(G.neighbors(curnode))\n",
    "      if not curnode in sampled_nodes:\n",
    "         sampled_nodes.add(curnode)\n",
    "         sampled_edges |= set([(min(curnode, neighbor), max(curnode, neighbor)) for neighbor in neighbors])\n",
    "      degree_x = len(neighbors) # We need to know the degree of the neighbor we're currently on\n",
    "      candidate = random.choice(neighbors) # We draw a potential node to visit at the next step\n",
    "      # We keep rejecting candidates if we extract a random number higher than the ratio between current node degree and candidate degree\n",
    "      while random.random() >= (degree_x / G.degree(candidate)): \n",
    "         candidate = random.choice(neighbors)\n",
    "      curnode = candidate\n",
    "   return nx.Graph(list(sampled_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take 100 samples and store their degree exponent in a list\n",
    "smpl_exponents = []\n",
    "for _ in range(100):\n",
    "   G_smpl = mhrw(G, 2000)\n",
    "   G_smpl_ccdf = ccdf(Counter(dict(G_smpl.degree).values()))\n",
    "   smpl_exponents.append(dd_exponent(G_smpl_ccdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Exponent: -1.3857 (+/- 0.0633)\n"
     ]
    }
   ],
   "source": [
    "smpl_exponents_mean = np.mean(smpl_exponents)\n",
    "smpl_exponents_std = np.std(smpl_exponents)\n",
    "print(\"Sample Exponent: %1.4f (+/- %1.4f)\" % (smpl_exponents_mean, smpl_exponents_std)) # The exponent of the sample is ~1.4, much closer to the original 1.6 than either RW and RWRW"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
